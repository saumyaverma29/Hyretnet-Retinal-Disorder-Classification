{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13586296,"sourceType":"datasetVersion","datasetId":8631833}],"dockerImageVersionId":31240,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import to_categorical\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset_path = \"/kaggle/input/minor-dataset/Data_Minor\"\n\nclasses = [\"HR\", \"DR\", \"RVO\"]\nnum_classes = len(classes)\n\nimg_size = (224, 224)\ninput_shape = (224, 224, 3)\n\nbatch_size = 8\nepochs = 25\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def apply_clahe(image):\n    lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n    l, a, b = cv2.split(lab)\n    clahe = cv2.createCLAHE(2.0, (8,8))\n    l = clahe.apply(l)\n    return cv2.cvtColor(cv2.merge((l,a,b)), cv2.COLOR_LAB2RGB)\n\ndef preprocess_image(image, use_preprocessing=True):\n    if use_preprocessing:\n        image = apply_clahe(image)\n    return image.astype(np.float32) / 255.0\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_images(use_preprocessing=True):\n    images, labels = [], []\n    for label, cls in enumerate(classes):\n        folder = os.path.join(dataset_path, cls)\n        for f in os.listdir(folder):\n            img = cv2.imread(os.path.join(folder, f))\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            img = cv2.resize(img, img_size)\n            img = preprocess_image(img, use_preprocessing)\n            images.append(img)\n            labels.append(label)\n    return np.array(images), np.array(labels)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_split(images, labels):\n    return train_test_split(\n        images, labels,\n        test_size=0.2,\n        stratify=labels,\n        random_state=42\n    )\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def build_cnn(input_shape, num_classes):\n    model = models.Sequential([\n        layers.Conv2D(32, 3, activation='relu', input_shape=input_shape),\n        layers.MaxPooling2D(),\n        layers.Conv2D(64, 3, activation='relu'),\n        layers.MaxPooling2D(),\n        layers.Conv2D(128, 3, activation='relu'),\n        layers.GlobalAveragePooling2D(),\n        layers.Dense(128, activation='relu'),\n        layers.Dense(num_classes, activation='softmax')\n    ])\n    return model\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def transformer_block(x, num_heads=4, ff_dim=128):\n    attn = layers.MultiHeadAttention(num_heads, key_dim=x.shape[-1])(x, x)\n    x = layers.Add()([x, attn])\n    x = layers.LayerNormalization()(x)\n\n    ff = layers.Dense(ff_dim, activation='relu')(x)\n    ff = layers.Dense(x.shape[-1])(ff)\n    x = layers.Add()([x, ff])\n    return layers.LayerNormalization()(x)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def build_transformer(input_shape, num_classes, patch_size=16, embed_dim=64):\n    inputs = layers.Input(shape=input_shape)\n\n    # Patch extraction\n    patches = layers.Conv2D(\n        embed_dim,\n        kernel_size=patch_size,\n        strides=patch_size,\n        padding=\"valid\"\n    )(inputs)\n\n    # Flatten patches\n    x = layers.Reshape((-1, embed_dim))(patches)\n\n    # Transformer encoder\n    for _ in range(2):\n        x = transformer_block(x, num_heads=4, ff_dim=128)\n\n    x = layers.GlobalAveragePooling1D()(x)\n    x = layers.Dense(128, activation='relu')(x)\n    outputs = layers.Dense(num_classes, activation='softmax')(x)\n\n    return models.Model(inputs, outputs)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def build_hybrid(input_shape, num_classes):\n    inputs = layers.Input(shape=input_shape)\n\n    # CNN feature extractor\n    x = layers.Conv2D(32, 3, activation='relu')(inputs)\n    x = layers.MaxPooling2D()(x)\n    x = layers.Conv2D(64, 3, activation='relu')(x)\n    x = layers.MaxPooling2D()(x)\n\n    # Flatten spatial â†’ tokens\n    x = layers.Reshape((-1, 64))(x)\n\n    # Transformer encoder\n    for _ in range(2):\n        x = transformer_block(x, num_heads=4, ff_dim=128)\n\n    x = layers.GlobalAveragePooling1D()(x)\n    x = layers.Dense(128, activation='relu')(x)\n    outputs = layers.Dense(num_classes, activation='softmax')(x)\n\n    return models.Model(inputs, outputs)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_and_eval(model, X_train, y_train, X_test, y_test):\n    model.compile(\n        optimizer=Adam(1e-4),\n        loss=\"categorical_crossentropy\",\n        metrics=[\"accuracy\"]\n    )\n\n    model.fit(\n        X_train, to_categorical(y_train, num_classes),\n        epochs=epochs,\n        batch_size=batch_size,\n        verbose=0\n    )\n\n    preds = np.argmax(model.predict(X_test), axis=1)\n    return accuracy_score(y_test, preds)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results = []\n\nfor use_preprocessing in [False, True]:\n    images, labels = load_images(use_preprocessing)\n    X_train, X_test, y_train, y_test = get_split(images, labels)\n\n    for name, builder in [\n        (\"CNN Only\", build_cnn),\n        (\"Transformer Only\", build_transformer),\n        (\"Hybrid CNN+Transformer\", build_hybrid)\n    ]:\n        model = builder(input_shape, num_classes)\n        acc = train_and_eval(model, X_train, y_train, X_test, y_test)\n\n        results.append([\n            name,\n            \"Yes\" if use_preprocessing else \"No\",\n            f\"{acc*100:.2f}%\"\n        ])\n\n        print(f\"{name} | Preprocessing: {use_preprocessing} | Acc: {acc:.4f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.DataFrame(\n    results,\n    columns=[\"Model\", \"Preprocessing\", \"Test Accuracy\"]\n)\n\nprint(\"\\nABLATION STUDY RESULTS\")\nprint(df.to_markdown(index=False))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}